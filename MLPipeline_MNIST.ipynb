{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipelines\n",
    "\n",
    "A Machine Learning pipeline is a set of independent steps that each can have different compute, data, environment, etc. dependencies. Each step is treated as a separate run and all of the four aspects of a run (metrics, logs, snapshot and outputs) are stored independently. After the pipeline is created, it can be published as an API for later reuse.\n",
    "\n",
    "This gives you huge benefit as you have ultimate control over defining each step of the pipeline in a way that serves best for that particular step.\n",
    "\n",
    "ML Pipelines are some type of workflow orchestration tools. The main difference between ML Pipelines and regular job workflows (such as Azure Data Factory or Airflow) is that this workflow engine is designed to address ML needs. Therefore, if you have non-ML related workflow it's recommended you use generic workflow engines. You may call an ML Pipeline from a generic pipeline as a step.\n",
    "\n",
    "In this tutorial, we want to treat the MNIST model we trained in the previous example like a serious ML problem. We'd like to break the task into three parts:\n",
    "1. Downloading the dataset from the Yann Lecun website, unzip and normalize it and save it in a shared storage\n",
    "2. Train our 2-Layer Neural Net on the normalized data\n",
    "3. Register the model in case the performance of the new model is higher than the latest version of the model in the Model Registry\n",
    "4. Publish the pipeline as a bundle of the above steps as an API Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining an ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.83\n",
      "Pipeline SDK-specific imports completed\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "print(\"Pipeline SDK-specific imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your subscription ID will be different replace the stirng with yours\n",
    "subscription_id = \"3df1840f-dd4b-4f54-a831-e20536439b3a\"\n",
    "resource_group = \"AzureML\"\n",
    "workspace_name = \"MTDemoWUS2\"\n",
    "workspace_region = \"westus2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Workspace class and check the azureml SDK version\n",
    "# exist_ok checks if workspace exists or not.\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: MTDemoWUS2\n",
      "Azure region: westus2\n",
      "Subscription id: 3df1840f-dd4b-4f54-a831-e20536439b3a\n",
      "Resource group: AzureML\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Stores\n",
    "\n",
    "As described in the previous section, Datastores are attached to workspaces and are used to store connection information to Azure storage services so you can refer to them by name and don't need to remember the connection information and secret used to connect to the storage services.\n",
    "\n",
    "https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore.datastore?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the registered Datastores in your Workspace, login to **ml.azure.com**, in the left pane, under **Manage** section click on the **Datastores**. By default, you have two data stores registered, **workspaceblobstore** and **workspacefilestore**.\n",
    "\n",
    "We skip the **workspacefilestore** for now and only use **workspaceblobstore** for this exercise. **workspaceblobstore** is referring to the default Blob storage that is created at the creation of Workspace. **Blob storage** is a type of storage account that is used to keep any type of data from binary (image files) to csv or parquet (It's similar to **AWS S3**). At any time you can register a new Azure's storage account at your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blobstore's name: workspaceblobstore\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the pointer to the default Blob storage.\n",
    "\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "\n",
    "## The code below also yields the same result:\n",
    "# def_blob_store = ws.get_default_datastore()\n",
    "\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An object from DataReference class represents a path within a Datastore. So in the example below, you're explaining that the MNIST data should be available in the **mnist_datainput** parth under the **workspaceblobstore** container in the Azure storage account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blob_input_data = DataReference(\n",
    "#     datastore=def_blob_store,\n",
    "#     data_reference_name=\"mnist_datainput\",\n",
    "#     path_on_datastore=\"mnist_datainput\")\n",
    "# \n",
    "# print(\"DataReference object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure the compute targets are created.\n",
    "\n",
    "In this example, we want to have two types of compute environment, the first compute type is a CPU type and the other is a GPU type cluster each with 1 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "Succeeded..................\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 1, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-02-11T17:10:59.293000+00:00', 'errors': None, 'creationTime': '2020-02-11T17:09:09.520135+00:00', 'modifiedTime': '2020-02-11T17:09:25.394500+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': ''}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Create a GPU cluster of type NV6 with 1 node. (due to subscription's limitations we stick to 1 node)\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target_cpu = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    # CPU: Standard_D3_v2\n",
    "    # GPU: Standard_NV6\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
    "                                                           max_nodes=1,\n",
    "                                                           min_nodes=1)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target_cpu = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target_cpu.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target_cpu.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Commenting this as we want to only use one compute target to make things faster. Try this later if you like to train on GPU.\n",
    "\n",
    "# # choose a name for your cluster\n",
    "# cluster_name = \"gpucluster\"\n",
    "# \n",
    "# try:\n",
    "#     compute_target_gpu = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "#     print('Found existing compute target.')\n",
    "# except ComputeTargetException:\n",
    "#     print('Creating a new compute target...')\n",
    "#     # CPU: Standard_D3_v2\n",
    "#     # GPU: Standard_NV6\n",
    "#     compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NV6', \n",
    "#                                                            max_nodes=1,\n",
    "#                                                            min_nodes=1)\n",
    "# \n",
    "#     # create the cluster\n",
    "#     compute_target_gpu = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "# \n",
    "#     compute_target_gpu.wait_for_completion(show_output=True)\n",
    "# \n",
    "# # use get_status() to get a detailed status for the current cluster. \n",
    "# print(compute_target_gpu.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpuclusterNV\n",
      "cpucluster\n"
     ]
    }
   ],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PipelineData is a way to define data dependancies in an ML Pipeline. In this example, we want to first download the MNIST data into a directory called raw_data and then save the processed and normalized numpy objects into a subdirectory called Processed. This PipelineData object will be used as the output of the first step named Data Extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_processed_mnist_data"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_mnist_data = PipelineData(\"processed_mnist_data\", datastore=def_blob_store)\n",
    "processed_mnist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step is a regular Python script, and can be executed on a CPU node with no prepackaged ML environment requirment, we stick to the default configurations.\n",
    "\n",
    "The configurations below, first deploys a CPU based linux docker image on the VM and then installs 'azureml-sdk' and 'numpy' packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# create a new runconfig object\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# enable Docker \n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# set Docker base image to the default CPU-based image\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk',\n",
    "                                                                                          'numpy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the first step by defining an object from PythonScriptStep class. Under the hood, it calls the extract.py file as the entry script and we pass the **processed_mnist_data** object as a parameter to the script.\n",
    "\n",
    "**outputs** parameter defines the data output dependencies that in this case, we have an object of DataPipeline **processed_mnist_data** as the output dependency.\n",
    "\n",
    "As the script can run on a CPU node, we don't waste our money by running it on a GPU node. Therefore, we select **compute_target_cpu** as the target compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extraction Step created\n"
     ]
    }
   ],
   "source": [
    "# source directory\n",
    "source_directory = 'DataExtraction'\n",
    "\n",
    "extractDataStep = PythonScriptStep(\n",
    "    script_name=\"extract.py\", \n",
    "    arguments=[\"--output_extract\", processed_mnist_data],\n",
    "    outputs=[processed_mnist_data],\n",
    "    compute_target=compute_target_cpu, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config)\n",
    "\n",
    "print(\"Data Extraction Step created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to run our Tensorflow job to train our very best MNIST classifier. As this is a TF job, we can leverage Estimator classes such as  **azureml.train.dnn.TensorFlow**. Moreover, the inputs argument instructs the Pipeline what should be the dependency before executing this step. As the **processed_mnist_data** PipelineData object is provided as the output for the step above and input for this step, the Pipeline engine will execute the Training step after the Data Extraction step.\n",
    "\n",
    "As a TF job, we can leverage our GPU node to boost up the computational performance of the training step. So we provide the GPU cluster as the compute target.\n",
    "\n",
    "The TF estimator support TF 1. If your script is based on TF 2, then you can use the **PythonScriptStep** and provide your custom docker image or pip install TF 2 on a base GPU image.\n",
    "\n",
    "We provide two arguments, **release_id** and **model_name**. **release_id** helps us to logically tag the run to a number that later can be retrieved. You can think of the **release_id** as the version number. In the 3rd day, you'll use the release pipeline to populate the release_id. **model_name** as it's name suggests instructs the code on what name to use to save the model in the run->output section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "source_directory = 'Training'\n",
    "est = TensorFlow(source_directory=source_directory,\n",
    "                 compute_target=compute_target_cpu,\n",
    "                 entry_script='train.py', \n",
    "                 use_gpu=False, \n",
    "                 framework_version='1.13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Step is Completed\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import EstimatorStep\n",
    "\n",
    "trainingStep = EstimatorStep(name=\"Training-Step\",\n",
    "                             estimator=est,\n",
    "                             estimator_entry_script_arguments=[\"--input_data_location\", processed_mnist_data,\n",
    "                                                               '--batch-size', 50,\n",
    "                                                               '--first-layer-neurons', 300,\n",
    "                                                               '--second-layer-neurons', 100,\n",
    "                                                               '--learning-rate', 0.01,\n",
    "                                                               \"--release_id\", 0,\n",
    "                                                               '--model_name', 'tf_mnist_pipeline.model'],\n",
    "                             runconfig_pipeline_params=None,\n",
    "                             inputs=[processed_mnist_data],\n",
    "                             compute_target=compute_target_cpu)\n",
    "\n",
    "print(\"Model Training Step is Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we want to evaluate and register the model. Similar to the first step, we only need a CPU node to accomplish this task as we're running a regular python script with no ML dependencies. So we instantiate an object from **PythonScriptStep** class and provide **evaluate_model.py** as the entry script. \n",
    "\n",
    "The two arguments we provided in the step above are used here to retrieve the model saved in the run->output section of the experiment. Using release id, we can retrieve all other models and check if this model is outperforming them or not. If not we don't register this model into the model registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation and Registration Step is Created\n"
     ]
    }
   ],
   "source": [
    "# source directory\n",
    "source_directory = 'RegisterModel'\n",
    "\n",
    "modelEvalReg = PythonScriptStep(\n",
    "    name=\"Evaluate and Register Model\",\n",
    "    script_name=\"evaluate_model.py\", \n",
    "    arguments=[\"--release_id\", 0,\n",
    "               '--model_name', 'tf_mnist_pipeline.model'],\n",
    "    compute_target=compute_target_cpu, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config)\n",
    "print(\"Model Evaluation and Registration Step is Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this step doesn't have any inputs or outputs data dependancies, the Pipeline engine will execute it in parallel with the prevous two steps. However, logically we should execute this after the training step. Therefore, we use the below command the instruct the Pipeline engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvalReg.run_after(trainingStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all of the pipeline steps are defined. We can build the Pipeline class which defines how the pipeline should be executed.\n",
    "\n",
    "Pipelines are loosely coupled with Experiments. At run time you can define to which Experiment this pipeline execution should be connected. For this we define/connect to **MNIST-Model-Manual-Pipeline** experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step extract.py [b8a66661][4ade047e-4fc1-47bb-b791-12db36c517d6], (This step will run and generate new outputs)\n",
      "Created step Training-Step [9c7faff8][72f50258-c5b0-47a2-befa-af52749e1961], (This step will run and generate new outputs)\n",
      "Created step Evaluate and Register Model [b951c1ca][917b1e8d-91f7-4329-9531-74bfe10d87de], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun a88b0aa0-9770-4a24-b836-da255cc493f5\n",
      "Link to Azure Machine Learning studio: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/a88b0aa0-9770-4a24-b836-da255cc493f5?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/AzureML/workspaces/MTDemoWUS2\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "pipeline = Pipeline(workspace=ws, steps=[extractDataStep, trainingStep, modelEvalReg])\n",
    "pipeline_run = Experiment(ws, 'MNIST-Model-Manual-Pipeline').submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366f8f76260a46e1838c019cf48f29af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/a88b0aa0-9770-4a24-b836-da255cc493f5?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/AzureML/workspaces/MTDemoWUS2\", \"run_id\": \"a88b0aa0-9770-4a24-b836-da255cc493f5\", \"run_properties\": {\"run_id\": \"a88b0aa0-9770-4a24-b836-da255cc493f5\", \"created_utc\": \"2020-02-11T17:12:16.835881Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-02-11T17:20:47.075649Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.a88b0aa0-9770-4a24-b836-da255cc493f5/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=22EbgwzuSICo28%2BgK1KCDntlERyd9%2FNw9kuQRPkcrJc%3D&st=2020-02-11T17%3A19%3A22Z&se=2020-02-12T01%3A29%3A22Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.a88b0aa0-9770-4a24-b836-da255cc493f5/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=DcBh7k0UtcCPX7fSVezmsxYIrjoW6CO%2B6H8s%2BeOjYlw%3D&st=2020-02-11T17%3A19%3A22Z&se=2020-02-12T01%3A29%3A22Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.a88b0aa0-9770-4a24-b836-da255cc493f5/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=NyZOWzIWAA5Q1OoZl%2FvJ3j95qlhZM5%2FhF8sMe2he4JQ%3D&st=2020-02-11T17%3A19%3A22Z&se=2020-02-12T01%3A29%3A22Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:08:30\"}, \"child_runs\": [{\"run_id\": \"2f967d88-5331-43b8-88a9-57e924b2619a\", \"name\": \"extract.py\", \"status\": \"Finished\", \"start_time\": \"2020-02-11T17:13:02.262079Z\", \"created_time\": \"2020-02-11T17:12:24.906779Z\", \"end_time\": \"2020-02-11T17:15:33.428574Z\", \"duration\": \"0:03:08\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-02-11T17:12:24.906779Z\", \"is_reused\": \"\"}, {\"run_id\": \"e813137c-c68a-42e6-a3a7-8810c39d8255\", \"name\": \"Training-Step\", \"status\": \"Finished\", \"start_time\": \"2020-02-11T17:15:54.649184Z\", \"created_time\": \"2020-02-11T17:15:38.821168Z\", \"end_time\": \"2020-02-11T17:18:49.463173Z\", \"duration\": \"0:03:10\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-02-11T17:15:38.821168Z\", \"is_reused\": \"\"}, {\"run_id\": \"404e1b36-58f3-4f90-ad9f-8516ef3419a1\", \"name\": \"Evaluate and Register Model\", \"status\": \"Finished\", \"start_time\": \"2020-02-11T17:19:48.613114Z\", \"created_time\": \"2020-02-11T17:18:56.174388Z\", \"end_time\": \"2020-02-11T17:20:38.299662Z\", \"duration\": \"0:01:42\", \"run_number\": 4, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-02-11T17:18:56.174388Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-02-11 17:12:24Z] Submitting 1 runs, first five are: b8a66661:2f967d88-5331-43b8-88a9-57e924b2619a\\n[2020-02-11 17:15:38Z] Completing processing run id 2f967d88-5331-43b8-88a9-57e924b2619a.\\n[2020-02-11 17:15:38Z] Submitting 1 runs, first five are: 9c7faff8:e813137c-c68a-42e6-a3a7-8810c39d8255\\n[2020-02-11 17:18:55Z] Completing processing run id e813137c-c68a-42e6-a3a7-8810c39d8255.\\n[2020-02-11 17:18:56Z] Submitting 1 runs, first five are: b951c1ca:404e1b36-58f3-4f90-ad9f-8516ef3419a1\\n[2020-02-11 17:20:45Z] Completing processing run id 404e1b36-58f3-4f90-ad9f-8516ef3419a1.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"b8a66661\": {\"node_id\": \"b8a66661\", \"name\": \"extract.py\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"2f967d88-5331-43b8-88a9-57e924b2619a\"}, \"9c7faff8\": {\"node_id\": \"9c7faff8\", \"name\": \"Training-Step\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"e813137c-c68a-42e6-a3a7-8810c39d8255\"}, \"b951c1ca\": {\"node_id\": \"b951c1ca\", \"name\": \"Evaluate and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"404e1b36-58f3-4f90-ad9f-8516ef3419a1\"}}, \"edges\": [{\"source_node_id\": \"b8a66661\", \"source_node_name\": \"extract.py\", \"source_name\": \"processed_mnist_data\", \"target_name\": \"processed_mnist_data\", \"dst_node_id\": \"9c7faff8\", \"dst_node_name\": \"Training-Step\"}, {\"source_node_id\": \"9c7faff8\", \"source_node_name\": \"Training-Step\", \"source_name\": \"_run_after_output\", \"target_name\": \"_run_after_input_0\", \"dst_node_id\": \"b951c1ca\", \"dst_node_name\": \"Evaluate and Register Model\"}], \"child_runs\": [{\"run_id\": \"2f967d88-5331-43b8-88a9-57e924b2619a\", \"name\": \"extract.py\", \"status\": \"Finished\", \"start_time\": \"2020-02-11T17:13:02.262079Z\", \"created_time\": \"2020-02-11T17:12:24.906779Z\", \"end_time\": \"2020-02-11T17:15:33.428574Z\", \"duration\": \"0:03:08\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-02-11T17:12:24.906779Z\", \"is_reused\": \"\"}, {\"run_id\": \"e813137c-c68a-42e6-a3a7-8810c39d8255\", \"name\": \"Training-Step\", \"status\": \"Finished\", \"start_time\": \"2020-02-11T17:15:54.649184Z\", \"created_time\": \"2020-02-11T17:15:38.821168Z\", \"end_time\": \"2020-02-11T17:18:49.463173Z\", \"duration\": \"0:03:10\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-02-11T17:15:38.821168Z\", \"is_reused\": \"\"}, {\"run_id\": \"404e1b36-58f3-4f90-ad9f-8516ef3419a1\", \"name\": \"Evaluate and Register Model\", \"status\": \"Finished\", \"start_time\": \"2020-02-11T17:19:48.613114Z\", \"created_time\": \"2020-02-11T17:18:56.174388Z\", \"end_time\": \"2020-02-11T17:20:38.299662Z\", \"duration\": \"0:01:42\", \"run_number\": 4, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-02-11T17:18:56.174388Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.83\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a081c0262bc440b8c9155e92f67e5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to any run, Pipeline runs are non-blocking. However, if you automate this job, you like your code to wait until the pipeline is constructed and executed. So you'd use the below command to make the run execution blocking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: a88b0aa0-9770-4a24-b836-da255cc493f5\n",
      "Link to Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/a88b0aa0-9770-4a24-b836-da255cc493f5?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/AzureML/workspaces/MTDemoWUS2\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 2f967d88-5331-43b8-88a9-57e924b2619a\n",
      "Link to Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/2f967d88-5331-43b8-88a9-57e924b2619a?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/AzureML/workspaces/MTDemoWUS2\n",
      "StepRun( extract.py ) Status: NotStarted\n",
      "StepRun( extract.py ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "========================================================================================================================\n",
      "2020-02-11T17:13:12Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_48d232ed44cf5529612187908604176e\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "61c64277f441: Pulling fs layer\n",
      "ac542d2a8acd: Pulling fs layer\n",
      "69882c0ac442: Pulling fs layer\n",
      "dac24d75e4d2: Pulling fs layer\n",
      "30c814362356: Pulling fs layer\n",
      "dd85232a5ba3: Pulling fs layer\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "61c64277f441: Waiting\n",
      "ac542d2a8acd: Waiting\n",
      "69882c0ac442: Waiting\n",
      "dac24d75e4d2: Waiting\n",
      "30c814362356: Waiting\n",
      "dd85232a5ba3: Waiting\n",
      "6504d449e70c: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "8269c605f3f1: Waiting\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "9b0d3db6dc03: Verifying Checksum\n",
      "9b0d3db6dc03: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "61c64277f441: Verifying Checksum\n",
      "61c64277f441: Download complete\n",
      "69882c0ac442: Verifying Checksum\n",
      "69882c0ac442: Download complete\n",
      "dac24d75e4d2: Verifying Checksum\n",
      "dac24d75e4d2: Download complete\n",
      "ac542d2a8acd: Verifying Checksum\n",
      "ac542d2a8acd: Download complete\n",
      "dd85232a5ba3: Verifying Checksum\n",
      "dd85232a5ba3: Download complete\n",
      "30c814362356: Verifying Checksum\n",
      "30c814362356: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "61c64277f441: Pull complete\n",
      "ac542d2a8acd: Pull complete\n",
      "69882c0ac442: Pull complete\n",
      "dac24d75e4d2: Pull complete\n",
      "30c814362356: Pull complete\n",
      "dd85232a5ba3: Pull complete\n",
      "Digest: sha256:89e9480f8f428d95efcdb3fedce682fbf6ade40bf455477019ce068d4ff1ff65\n",
      "Status: Downloaded newer image for mtdemowuacrvarjlhdq.azurecr.io/azureml/azureml_48d232ed44cf5529612187908604176e:latest\n",
      "09f79efb59a6c471ef90223e827928f67008d54c414d5947967d6b8a6e75884d\n",
      "2020/02/11 17:14:28 Version: 3.0.01110.0001 Branch: master Commit: ab88b58d\n",
      "2020/02/11 17:14:29 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/02/11 17:14:29 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job preparation. Current time:2020-02-11T17:14:37.852753\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "Retrieving project from snapshot: 068d2de6-83a3-45ef-befe-e333c6212004\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 88\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 138\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ extract.py ] with arguments: ['--output_extract', '/mnt/batch/tasks/shared/LS_root/jobs/mtdemowus2/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/mounts/workspaceblobstore/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data']\n",
      "After variable expansion, calling script [ extract.py ] with arguments: ['--output_extract', '/mnt/batch/tasks/shared/LS_root/jobs/mtdemowus2/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/mounts/workspaceblobstore/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data']\n",
      "\n",
      "Argument 1: /mnt/batch/tasks/shared/LS_root/jobs/mtdemowus2/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/mounts/workspaceblobstore/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data\n",
      "Files are downloaded to /mnt/batch/tasks/shared/LS_root/jobs/mtdemowus2/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/mounts/workspaceblobstore/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data/raw_files/\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job release. Current time:2020-02-11T17:15:07.142753\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 175\n",
      "Job release is complete. Current time:2020-02-11T17:15:09.355450\n",
      "\n",
      "StepRun(extract.py) Execution Summary\n",
      "======================================\n",
      "StepRun( extract.py ) Status: Finished\n",
      "{'runId': '2f967d88-5331-43b8-88a9-57e924b2619a', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2020-02-11T17:13:02.262079Z', 'endTimeUtc': '2020-02-11T17:15:33.428574Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '068d2de6-83a3-45ef-befe-e333c6212004', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': 'a88b0aa0-9770-4a24-b836-da255cc493f5', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_48d232ed44cf5529612187908604176e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'extract.py', 'useAbsolutePath': False, 'arguments': ['--output_extract', '$AZUREML_DATAREFERENCE_processed_mnist_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {'processed_mnist_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment MNIST-Model-Manual-Pipeline Environment', 'version': 'Autosave_2020-02-11T17:12:29Z_daec9ce0', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk==1.0.83.*', 'numpy']}], 'name': 'azureml_91c1fb35d3712e5a616a52c0ebfdf21c'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=qCa2aefchxw1iprIxLnYuuSSkhGB21FnZgC5I5kGoCo%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=p8JsoN0aFYhiqpUAq%2F7OkiI3%2F8guGLkvysIWYHTpMVU%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=b688ZRXmlk%2BWcpbH2SLjCY1zlV54nOa9karpqKILtMQ%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=ui3MxCtB24tlmnc34g9Fh4ITSnwg%2BwfGW71XMUhoM%2Fg%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'azureml-logs/process_info.json': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=x89eVKt3TU9TPH5517PXUHx8CO1L6IfO%2FOPUPlk17jM%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'azureml-logs/process_status.json': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=fF72Njt9pZ%2B8JmYx3a8X6KjSmqFWBwdxyDCzUw9fGrE%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'logs/azureml/138_azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/logs/azureml/138_azureml.log?sv=2019-02-02&sr=b&sig=HSSYVGXUls47fqPEwx0JO4Wj04fc7eddQpvkDuLX1Lc%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=cYWeqad2MqEKQVnO032TIPPNppiIh3%2FgFzkvQ9YaAXQ%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=BxC2lYV5DqSDfUo%2BUyUkc%2BiG%2Br4oWkpFHGiBReldbJE%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=ZSUJFTC1kDnynJJmpsCQaQohScJZXU0Pod66Vi02dwY%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=g65Aski%2FW49AhaSm6lStWKPl46FLkv8QvvCVn6%2FfreI%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.2f967d88-5331-43b8-88a9-57e924b2619a/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=oQm2n4oVD5E8MgopakkTvQjusra3n7Dj5nFLs6sk1zA%3D&st=2020-02-11T17%3A05%3A41Z&se=2020-02-12T01%3A15%3A41Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: e813137c-c68a-42e6-a3a7-8810c39d8255\n",
      "Link to Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/e813137c-c68a-42e6-a3a7-8810c39d8255?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/AzureML/workspaces/MTDemoWUS2\n",
      "StepRun( Training-Step ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "========================================================================================================================\n",
      "2020-02-11T17:15:56Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "1.13-cpu: Pulling from tensorflow\n",
      "16c48d79e9cc: Pulling fs layer\n",
      "3c654ad3ed7d: Pulling fs layer\n",
      "6276f4f9c29d: Pulling fs layer\n",
      "a4bd43ad48ce: Pulling fs layer\n",
      "e8d5220518a8: Pulling fs layer\n",
      "b89bc95dc4e6: Pulling fs layer\n",
      "874f36ef0b3a: Pulling fs layer\n",
      "20592f072a44: Pulling fs layer\n",
      "d5a9f64d93c8: Pulling fs layer\n",
      "bf16c69a1526: Pulling fs layer\n",
      "b47bfd667bdb: Pulling fs layer\n",
      "6a140fc11307: Pulling fs layer\n",
      "874f36ef0b3a: Waiting\n",
      "20592f072a44: Waiting\n",
      "d5a9f64d93c8: Waiting\n",
      "bf16c69a1526: Waiting\n",
      "b47bfd667bdb: Waiting\n",
      "6a140fc11307: Waiting\n",
      "a4bd43ad48ce: Waiting\n",
      "e8d5220518a8: Waiting\n",
      "b89bc95dc4e6: Waiting\n",
      "3c654ad3ed7d: Verifying Checksum\n",
      "3c654ad3ed7d: Download complete\n",
      "6276f4f9c29d: Verifying Checksum\n",
      "6276f4f9c29d: Download complete\n",
      "16c48d79e9cc: Verifying Checksum\n",
      "16c48d79e9cc: Download complete\n",
      "b89bc95dc4e6: Verifying Checksum\n",
      "b89bc95dc4e6: Download complete\n",
      "a4bd43ad48ce: Verifying Checksum\n",
      "a4bd43ad48ce: Download complete\n",
      "e8d5220518a8: Verifying Checksum\n",
      "e8d5220518a8: Download complete\n",
      "874f36ef0b3a: Verifying Checksum\n",
      "874f36ef0b3a: Download complete\n",
      "20592f072a44: Verifying Checksum\n",
      "20592f072a44: Download complete\n",
      "bf16c69a1526: Verifying Checksum\n",
      "bf16c69a1526: Download complete\n",
      "b47bfd667bdb: Verifying Checksum\n",
      "b47bfd667bdb: Download complete\n",
      "16c48d79e9cc: Pull complete\n",
      "3c654ad3ed7d: Pull complete\n",
      "6276f4f9c29d: Pull complete\n",
      "a4bd43ad48ce: Pull complete\n",
      "d5a9f64d93c8: Verifying Checksum\n",
      "d5a9f64d93c8: Download complete\n",
      "6a140fc11307: Verifying Checksum\n",
      "6a140fc11307: Download complete\n",
      "e8d5220518a8: Pull complete\n",
      "b89bc95dc4e6: Pull complete\n",
      "874f36ef0b3a: Pull complete\n",
      "20592f072a44: Pull complete\n",
      "d5a9f64d93c8: Pull complete\n",
      "bf16c69a1526: Pull complete\n",
      "b47bfd667bdb: Pull complete\n",
      "6a140fc11307: Pull complete\n",
      "Digest: sha256:a8598363b592586620449828598516d04540238b8bc50b7aac2a01cf3f9c7585\n",
      "Status: Downloaded newer image for viennaprivate.azurecr.io/tensorflow:1.13-cpu\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "===============================================================================================================\n",
      "Starting job preparation. Current time:2020-02-11T17:17:13.335493\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 125\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train.py ] with arguments: ['--input_data_location', '/mnt/batch/tasks/shared/LS_root/jobs/mtdemowus2/azureml/e813137c-c68a-42e6-a3a7-8810c39d8255/mounts/workspaceblobstore/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data', '--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.01', '--release_id', '0', '--model_name', 'tf_mnist_pipeline.model']\n",
      "After variable expansion, calling script [ train.py ] with arguments: ['--input_data_location', '/mnt/batch/tasks/shared/LS_root/jobs/mtdemowus2/azureml/e813137c-c68a-42e6-a3a7-8810c39d8255/mounts/workspaceblobstore/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data', '--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.01', '--release_id', '0', '--model_name', 'tf_mnist_pipeline.model']\n",
      "\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Argument input_data_location: /mnt/batch/tasks/shared/LS_root/jobs/mtdemowus2/azureml/e813137c-c68a-42e6-a3a7-8810c39d8255/mounts/workspaceblobstore/azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data\n",
      "Argument n_h1: 300\n",
      "Argument n_h2: 100\n",
      "Argument learning_rate: 0.01\n",
      "Argument batch_size: 50\n",
      "Argument release_id: 0\n",
      "Argument model_name: tf_mnist_pipeline.model\n",
      "Numpy binary data is loaded\n",
      "WARNING:tensorflow:From train.py:77: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /opt/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2020-02-11 17:17:24.566224: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-02-11 17:17:24.571059: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294685000 Hz\n",
      "2020-02-11 17:17:24.571303: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557b956252a0 executing computations on platform Host. Devices:\n",
      "2020-02-11 17:17:24.571450: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "0 -- Training accuracy: 0.94 Validation accuracy: 0.9021\n",
      "1 -- Training accuracy: 0.9 Validation accuracy: 0.919\n",
      "2 -- Training accuracy: 0.94 Validation accuracy: 0.9297\n",
      "3 -- Training accuracy: 0.94 Validation accuracy: 0.9355\n",
      "4 -- Training accuracy: 0.94 Validation accuracy: 0.9434\n",
      "5 -- Training accuracy: 1.0 Validation accuracy: 0.9484\n",
      "6 -- Training accuracy: 1.0 Validation accuracy: 0.9511\n",
      "7 -- Training accuracy: 0.98 Validation accuracy: 0.9542\n",
      "8 -- Training accuracy: 1.0 Validation accuracy: 0.9569\n",
      "9 -- Training accuracy: 1.0 Validation accuracy: 0.9602\n",
      "10 -- Training accuracy: 1.0 Validation accuracy: 0.963\n",
      "11 -- Training accuracy: 0.98 Validation accuracy: 0.9631\n",
      "12 -- Training accuracy: 0.98 Validation accuracy: 0.965\n",
      "13 -- Training accuracy: 0.98 Validation accuracy: 0.966\n",
      "14 -- Training accuracy: 0.96 Validation accuracy: 0.9666\n",
      "15 -- Training accuracy: 1.0 Validation accuracy: 0.969\n",
      "16 -- Training accuracy: 1.0 Validation accuracy: 0.9696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 -- Training accuracy: 0.98 Validation accuracy: 0.9704\n",
      "18 -- Training accuracy: 0.98 Validation accuracy: 0.9709\n",
      "19 -- Training accuracy: 0.96 Validation accuracy: 0.9711\n",
      "added properties: {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'b69c209b-3e2c-4d79-8253-5b6fca98f6e0', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': 'a88b0aa0-9770-4a24-b836-da255cc493f5', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'release_id': '0', 'run_type': 'train'}\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.2707364559173584 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 125\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2020-02-11T17:18:35.925274\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 279\n",
      "Job release is complete. Current time:2020-02-11T17:18:37.359891\n",
      "\n",
      "StepRun(Training-Step) Execution Summary\n",
      "=========================================\n",
      "StepRun( Training-Step ) Status: Finished\n",
      "{'runId': 'e813137c-c68a-42e6-a3a7-8810c39d8255', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2020-02-11T17:15:54.649184Z', 'endTimeUtc': '2020-02-11T17:18:49.463173Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'b69c209b-3e2c-4d79-8253-5b6fca98f6e0', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': 'a88b0aa0-9770-4a24-b836-da255cc493f5', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'release_id': '0', 'run_type': 'train'}, 'inputDatasets': [], 'runDefinition': {'script': 'train.py', 'useAbsolutePath': False, 'arguments': ['--input_data_location', '$AZUREML_DATAREFERENCE_processed_mnist_data', '--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.01', '--release_id', '0', '--model_name', 'tf_mnist_pipeline.model'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {'processed_mnist_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/2f967d88-5331-43b8-88a9-57e924b2619a/processed_mnist_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment MNIST-Model-Manual-Pipeline Environment', 'version': 'Autosave_2020-02-11T17:15:41Z_d146588f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'channels': ['conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'tensorflow:1.13-cpu', 'baseDockerfile': None, 'baseImageRegistry': {'address': 'viennaprivate.azurecr.io', 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': False}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=MqJgTmeLnrkEmV7XB%2BMxbgwfOrepRUL41wAjwgMNPtE%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=jp31IaBPXefWvYwLr4dS8WQ8JfMLDSCc9vJ%2B%2FPjnI6k%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=oWlTOpThlDfa5Ra%2BrFUoPCH5NNfuaX6HOLvjEy4MTr8%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=7e9WtcasJhfFcmiRu9NE4qNyWf0NcOImU3SrdKGNevY%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'azureml-logs/process_info.json': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=tQYToSrWJ3M19sg0imVdhvlBz0mc33cvn5STeEuqrMI%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'azureml-logs/process_status.json': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=G7Id2sahaoggEI0H%2F7HCfaHWYg4fHGYQlsSwEbmS7hA%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'logs/azureml/125_azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/logs/azureml/125_azureml.log?sv=2019-02-02&sr=b&sig=Aj2GfC3AAKNT5kAmSJsyzn7C0%2FOuIxGKjmHO2LZDmLQ%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'logs/azureml/azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=aLfFhuvV81ZZgDxXWcZHGwhFO4Q2KfzYExp6aOeZzDk%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=118mXMBC15pzuWbepoYr12cPGlBahzZBhEjScLXdX34%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=hg00cOFEWxBdcbpKss42RR9XNwz9JHbOotCguwiZu48%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.e813137c-c68a-42e6-a3a7-8810c39d8255/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=uw2twQR6xrgPVoD%2B29cBs3UMYQdMfgmypeAEESAipQs%3D&st=2020-02-11T17%3A08%3A57Z&se=2020-02-12T01%3A18%3A57Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 404e1b36-58f3-4f90-ad9f-8516ef3419a1\n",
      "Link to Portal: https://ml.azure.com/experiments/MNIST-Model-Manual-Pipeline/runs/404e1b36-58f3-4f90-ad9f-8516ef3419a1?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/AzureML/workspaces/MTDemoWUS2\n",
      "StepRun( Evaluate and Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "========================================================================================================================\n",
      "2020-02-11T17:19:36Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_48d232ed44cf5529612187908604176e\n",
      "Digest: sha256:89e9480f8f428d95efcdb3fedce682fbf6ade40bf455477019ce068d4ff1ff65\n",
      "Status: Image is up to date for mtdemowuacrvarjlhdq.azurecr.io/azureml/azureml_48d232ed44cf5529612187908604176e:latest\n",
      "fdb67bde09fc6e9727ceee4ed2139cb437dd9f7ede32cc273983f07fd289eb8b\n",
      "2020/02/11 17:19:41 Version: 3.0.01110.0001 Branch: master Commit: ab88b58d\n",
      "2020/02/11 17:19:41 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/02/11 17:19:41 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job preparation. Current time:2020-02-11T17:19:52.945638\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "Retrieving project from snapshot: 64442b94-43a0-4d03-b686-732176a9857d\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 88\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "Download from datastores if requested.\n",
      "Download or mount from datasets if requested.\n",
      "Job preparation is complete. Current time:2020-02-11T17:19:55.611609\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 138\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ evaluate_model.py ] with arguments: ['--release_id', '0', '--model_name', 'tf_mnist_pipeline.model']\n",
      "After variable expansion, calling script [ evaluate_model.py ] with arguments: ['--release_id', '0', '--model_name', 'tf_mnist_pipeline.model']\n",
      "\n",
      "Argument release_id: tf_mnist_pipeline.model\n",
      "Argument model_name: 0\n",
      "New Run found with Run ID of: e813137c-c68a-42e6-a3a7-8810c39d8255\n",
      "This is the first model to be trained,             thus nothing to evaluate for now\n",
      "Registered new model!\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "29 items cleaning up...\n",
      "Cleanup took 0.05374026298522949 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 138\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_91c1fb35d3712e5a616a52c0ebfdf21c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job release. Current time:2020-02-11T17:20:23.172120\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 201\n",
      "Job release is complete. Current time:2020-02-11T17:20:25.095609\n",
      "\n",
      "StepRun(Evaluate and Register Model) Execution Summary\n",
      "=======================================================\n",
      "StepRun( Evaluate and Register Model ) Status: Finished\n",
      "{'runId': '404e1b36-58f3-4f90-ad9f-8516ef3419a1', 'target': 'cpucluster', 'status': 'Completed', 'startTimeUtc': '2020-02-11T17:19:48.613114Z', 'endTimeUtc': '2020-02-11T17:20:38.299662Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '64442b94-43a0-4d03-b686-732176a9857d', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': 'a88b0aa0-9770-4a24-b836-da255cc493f5', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_48d232ed44cf5529612187908604176e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'evaluate_model.py', 'useAbsolutePath': False, 'arguments': ['--release_id', '0', '--model_name', 'tf_mnist_pipeline.model'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpucluster', 'dataReferences': {}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment MNIST-Model-Manual-Pipeline Environment', 'version': 'Autosave_2020-02-11T17:12:29Z_daec9ce0', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk==1.0.83.*', 'numpy']}], 'name': 'azureml_91c1fb35d3712e5a616a52c0ebfdf21c'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/azureml-logs/55_azureml-execution-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=SLVKkEBA44ZIRcgcv7%2BjtuIe8HJljegqc9jcEcIQ1vE%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/azureml-logs/65_job_prep-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=%2B9PskVVcAfYpFcfrykhakvOHgfJFnDUuokQ5Xkejqsg%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=ELu3NbhuZOANvQ2%2FKU4e0Y70GpRUfLXMh9rbFjuNmVE%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/azureml-logs/75_job_post-tvmps_40b39e140d2991f8567094f6ed60b10ecfab0b180aca6c6b5506f1816da8fc40_d.txt?sv=2019-02-02&sr=b&sig=4ZHCPmhzCJnSWPxYzy2GUm29EsG7YN3ECP2j1c01us4%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'azureml-logs/process_info.json': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=zpotyMw3pJ%2FxUVTiwnOpScA7TyNAjce5DWe7NN5skHs%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'azureml-logs/process_status.json': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=K4eRhrudm3xhGPrvRJZfJtYKJeJ0jMuKKz9rGFSr7xE%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'logs/azureml/138_azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/logs/azureml/138_azureml.log?sv=2019-02-02&sr=b&sig=v7s93FoCq40nXervlLLB1gbEwO4OecWUiJPMXE%2BL7i4%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=PjxOZEkIjuARYrvu2Ph6Cl%2F03CmJugn1j90A11FM28A%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=fwUS5Q9x3YGOJtXc07dQ2UVJ7K4aH8836T13Ew2MVhY%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=P4fcqXvA%2BthgCKrCk1mTNJ0hYVZzaKTqbunvfGvBhSY%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=EmV7SEmfB%2Fsi41MVdR0GvvWO3r04w0k%2BakNHSQumvOQ%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.404e1b36-58f3-4f90-ad9f-8516ef3419a1/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=JMcxxSdoV3%2BtjGQUDGKPKHkZh1jsVufQdiZ5L8JWdvQ%3D&st=2020-02-11T17%3A10%3A46Z&se=2020-02-12T01%3A20%3A46Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'a88b0aa0-9770-4a24-b836-da255cc493f5', 'status': 'Completed', 'startTimeUtc': '2020-02-11T17:12:21.163528Z', 'endTimeUtc': '2020-02-11T17:20:47.075649Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.a88b0aa0-9770-4a24-b836-da255cc493f5/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=2rEKPG2YDBr%2B2hukxyjh6NYUbjpUY3UzHNuEmuJ2pYc%3D&st=2020-02-11T17%3A10%3A49Z&se=2020-02-12T01%3A20%3A49Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.a88b0aa0-9770-4a24-b836-da255cc493f5/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=OfffUC3Rw4YK3EPTI3gBfR0%2BtjHz1Ws%2Bg3eAaaS8bYo%3D&st=2020-02-11T17%3A10%3A49Z&se=2020-02-12T01%3A20%3A49Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mtdemowustoragenogcjprd.blob.core.windows.net/azureml/ExperimentRun/dcid.a88b0aa0-9770-4a24-b836-da255cc493f5/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=m6OADMJgehKaC0mXeDeSCYGNgfJCofoGkicZGF3DEvs%3D&st=2020-02-11T17%3A10%3A49Z&se=2020-02-12T01%3A20%3A49Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion(show_output=True, raise_on_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Publish and trigger a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Pipeline is executed once under an experiment. But for later use, you may want to Publish the Pipeline as an Endpoint. publish_pipeline method publishes a pipeline under Pipeline section of Workspace. The published pipeline can later be called from any where inside or outside of Azure.\n",
    "\n",
    "One of the use-cases is to call the Pipeline within a Data Engineering Pipeline. So the Data Engineering team can trigger the piblished pipeline by having the URI information of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(name=\"MNIST-Pipeline-Manually-Built-Manulife\", \n",
    "                                                   description=\"Steps are: data preparation, training, model validation and model registration\", \n",
    "                                                   version=\"0.1\", \n",
    "                                                   continue_on_step_failure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>MNIST-Pipeline-Manually-Built-Manulife</td><td><a href=\"https://ml.azure.com/pipelines/4d24c718-0546-4237-8988-6b66daa815a7?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/AzureML/workspaces/MTDemoWUS2\" target=\"_blank\" rel=\"noopener\">4d24c718-0546-4237-8988-6b66daa815a7</a></td><td>Active</td><td><a href=\"https://westus2.aether.ms/api/v1.0/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourceGroups/AzureML/providers/Microsoft.MachineLearningServices/workspaces/MTDemoWUS2/PipelineRuns/PipelineSubmit/4d24c718-0546-4237-8988-6b66daa815a7\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: MNIST-Pipeline-Manually-Built-Manulife,\n",
       "Id: 4d24c718-0546-4237-8988-6b66daa815a7,\n",
       "Status: Active,\n",
       "Endpoint: https://westus2.aether.ms/api/v1.0/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourceGroups/AzureML/providers/Microsoft.MachineLearningServices/workspaces/MTDemoWUS2/PipelineRuns/PipelineSubmit/4d24c718-0546-4237-8988-6b66daa815a7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "\n",
    "pipeline_id = published_pipeline.id # use your published pipeline id\n",
    "published_pipeline = PublishedPipeline.get(ws, pipeline_id)\n",
    "published_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the endpoint that is callable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://westus2.aether.ms/api/v1.0/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourceGroups/AzureML/providers/Microsoft.MachineLearningServices/workspaces/MTDemoWUS2/PipelineRuns/PipelineSubmit/4d24c718-0546-4237-8988-6b66daa815a7'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "rest_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can call the Endpoint from anywhere. In order to call the endpoint, you need to authenticate yourself. There are two ways to do that:\n",
    "    \n",
    "    1. InteractiveLoginAuthentication\n",
    "    1. ServicePrincipalAuthentication\n",
    "    \n",
    "The first one requires you to authentical yourself interactively or be already authenticated. As we're already authenticated, so we can use the first approach. The second approach id described in the next section.\n",
    "\n",
    "The InteractiveLoginAuthentication class can help us generate the authentication key required to connect with the ML Pipeline Endpoint using **get_authentication_header** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "import requests\n",
    "\n",
    "auth = InteractiveLoginAuthentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkhsQzBSMTJza3hOWjFXUXdtak9GXzZ0X3RERSIsImtpZCI6IkhsQzBSMTJza3hOWjFXUXdtak9GXzZ0X3RERSJ9.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.djJqglQx63hcDqcWAjX_Mvm0DPWWWZkXFu1bDGzqK7OeoSo8lbqZ7OhQvXs9ONBYDa0A5kxeYfe9v4hLIGa0I2Aq38hNc7p9d7SPXaQTNlvSPv3aiOFgkC-WbYHoQIGsWrBeQvNE-94hT1Ky-xpMQF1sw3nCZuo9Wc6rJZxZHBdSJkAoLwFF7FaKlRaFEnEZw387UxCUxW2ZRvNYuqZq9XSZH-irKYFjtgjSNMzozVVg_bJSqmKEqWJk2-GPYn3yVt8iAOtpT78OYuSriP3rSOv4AihA7s9wToKdQHGQsJOklpLviuEyYElduAKqmTKY_y8HY3VTCAXfDFF9IPS0NQ'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aad_token = auth.get_authentication_header()\n",
    "aad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally using a simple post request, you can trigger the pipeline. Post request are available in any modern programming language, therefore, you can trigger the pipeline from anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the param when running the pipeline\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=aad_token, \n",
    "                         json={\"ExperimentName\": \"Kicked_MNist_Pipeline_Remotely\",\n",
    "                               \"RunSource\": \"SDK\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa8563ac-e772-4777-ab4b-568fc5a1db48\n"
     ]
    }
   ],
   "source": [
    "run_id = response.json()[\"Id\"]\n",
    "\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the Pipeline Run:\n",
    "\n",
    "from azureml.pipeline.core import PipelineRun\n",
    "\n",
    "exp = Experiment(name=\"Kicked_MNist_Pipeline_Remotely\", workspace=ws)\n",
    "pipeline_run = PipelineRun(experiment=exp, run_id=run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Schedule the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of using a Pipeline is to schedule it. In the example below, the pipeline is scheduled to be triggered weekly on Fridays at 15:30 UTC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "# \n",
    "# \n",
    "# recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Friday\"], time_of_day=\"15:30\")\n",
    "# schedule = Schedule.create(ws, name=\"ScheduledPipeline\", pipeline_id=pipeline_id,\n",
    "#                               experiment_name=\"MNIST-Pipeline-Wekly-Scheduled\", recurrence=recurrence)\n",
    "# \n",
    "## Get the list of scheduled Pipelines\n",
    "# Schedule.list(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add . && git commit -m \"Pipeline published and scheduled\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete compute resources\n",
    "\n",
    "Once this exercise is completed, you can delete disposable resources so you avoid getting unnecessary charges.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target_cpu.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
